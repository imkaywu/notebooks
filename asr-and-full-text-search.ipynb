{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Overview\n\nThis is a proof-of-concept implementation demonstrating that it's possible to use the ASR to generate transcript and use the said transcript to find the source content. This proposed method consists of the following steps:\n1. Audio to text conversion by ASR\n2. Text-based search\n  * a) Full-text search\n  * b) Semantic search using embedding\n\nIf ASR works well, then it's reasonable to assume that videos clips from the same source should generate similar texts, thus a simple full-text search should yield good result.\n","metadata":{"id":"tSr1Qw9a1Vp-"}},{"cell_type":"markdown","source":"## Dataset\n\nWe use the [Lexicap: Lex Fridman Podcast Whisper captions](https://karpathy.ai/lexicap/) dataset created by Karpathy. This serves as the asset for our demo.","metadata":{"id":"rG30F-mM8Awp"}},{"cell_type":"code","source":"! wget https://karpathy.ai/lexicap/data.zip","metadata":{"id":"VobiIV0N074g","colab":{"base_uri":"https://localhost:8080/"},"outputId":"102a4dfd-0db3-4af0-f6de-d0d7316af715","execution":{"iopub.status.busy":"2024-01-18T22:47:43.322476Z","iopub.execute_input":"2024-01-18T22:47:43.322946Z","iopub.status.idle":"2024-01-18T22:47:44.684132Z","shell.execute_reply.started":"2024-01-18T22:47:43.322904Z","shell.execute_reply":"2024-01-18T22:47:44.682661Z"},"trusted":true},"execution_count":265,"outputs":[{"name":"stdout","text":"--2024-01-18 22:47:44--  https://karpathy.ai/lexicap/data.zip\nResolving karpathy.ai (karpathy.ai)... 151.101.1.195, 151.101.65.195\nConnecting to karpathy.ai (karpathy.ai)|151.101.1.195|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 38234309 (36M) [application/zip]\nSaving to: 'data.zip'\n\ndata.zip            100%[===================>]  36.46M   166MB/s    in 0.2s    \n\n2024-01-18 22:47:44 (166 MB/s) - 'data.zip' saved [38234309/38234309]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!mkdir -p input && unzip -q \\*.zip -d input && rm *.zip","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fQDZaX4c3wM9","outputId":"2b2c67b4-4f18-4e11-81b4-7e1f3e2045ff","execution":{"iopub.status.busy":"2024-01-18T22:47:55.102001Z","iopub.execute_input":"2024-01-18T22:47:55.102463Z","iopub.status.idle":"2024-01-18T22:47:57.339863Z","shell.execute_reply.started":"2024-01-18T22:47:55.102423Z","shell.execute_reply":"2024-01-18T22:47:57.338214Z"},"trusted":true},"execution_count":266,"outputs":[]},{"cell_type":"code","source":"WORKING_PATH = '/kaggle/working'\nINPUT_PATH = f'{WORKING_PATH}/input'\nVTT_PATH = f'{INPUT_PATH}/vtt'","metadata":{"id":"KA0YI9JE6STZ","execution":{"iopub.status.busy":"2024-01-18T19:38:58.847695Z","iopub.execute_input":"2024-01-18T19:38:58.848536Z","iopub.status.idle":"2024-01-18T19:38:58.853646Z","shell.execute_reply.started":"2024-01-18T19:38:58.848493Z","shell.execute_reply":"2024-01-18T19:38:58.852714Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from os import linesep\ndef collate_transcript(file_path):\n  lines = []\n  with open(file_path) as fid:\n    while True:\n        line = fid.readline()\n\n        if 'WEBVTT' in line or '-->' in line or line == '\\n':\n          continue\n        if not line:\n            break\n\n        lines.append(line.rstrip())\n  transcript = ''.join(lines)\n  return transcript\n\n# transcript = collate_transcript('/content/input/vtt/episode_001_large.vtt')\n# transcript","metadata":{"id":"JWWi6gtU3zyI","execution":{"iopub.status.busy":"2024-01-18T19:30:57.647527Z","iopub.execute_input":"2024-01-18T19:30:57.648834Z","iopub.status.idle":"2024-01-18T19:30:57.656329Z","shell.execute_reply.started":"2024-01-18T19:30:57.648786Z","shell.execute_reply":"2024-01-18T19:30:57.655271Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from os import walk\nfrom os.path import join\n\nfilenames = []\nfor (dirpath, dirnames, fnames) in walk(VTT_PATH):\n    filenames.extend(fnames)\n    break\n\nfilenames = [fname for fname in filenames if 'large' in fname]\nfilenames.sort()\nfile_paths = [join(VTT_PATH, fname) for fname in filenames]\nfile_paths[:10]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_GxK0pwA44eg","outputId":"a5c1fe41-b14e-46cc-c02d-3c2d47432a57","execution":{"iopub.status.busy":"2024-01-18T19:30:59.387630Z","iopub.execute_input":"2024-01-18T19:30:59.388009Z","iopub.status.idle":"2024-01-18T19:30:59.400218Z","shell.execute_reply.started":"2024-01-18T19:30:59.387970Z","shell.execute_reply":"2024-01-18T19:30:59.399031Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['/kaggle/working/input/vtt/episode_001_large.vtt',\n '/kaggle/working/input/vtt/episode_002_large.vtt',\n '/kaggle/working/input/vtt/episode_003_large.vtt',\n '/kaggle/working/input/vtt/episode_004_large.vtt',\n '/kaggle/working/input/vtt/episode_005_large.vtt',\n '/kaggle/working/input/vtt/episode_006_large.vtt',\n '/kaggle/working/input/vtt/episode_007_large.vtt',\n '/kaggle/working/input/vtt/episode_008_large.vtt',\n '/kaggle/working/input/vtt/episode_009_large.vtt',\n '/kaggle/working/input/vtt/episode_010_large.vtt']"},"metadata":{}}]},{"cell_type":"code","source":"fname2idx = {}\nfor i, fname in enumerate(filenames):\n    fname2idx[fname] = i","metadata":{"execution":{"iopub.status.busy":"2024-01-18T22:07:34.839972Z","iopub.execute_input":"2024-01-18T22:07:34.840453Z","iopub.status.idle":"2024-01-18T22:07:34.845231Z","shell.execute_reply.started":"2024-01-18T22:07:34.840417Z","shell.execute_reply":"2024-01-18T22:07:34.844404Z"},"trusted":true},"execution_count":211,"outputs":[]},{"cell_type":"code","source":"transcripts = [collate_transcript(fname) for fname in file_paths]","metadata":{"id":"JBit_v2F49PN","execution":{"iopub.status.busy":"2024-01-18T19:31:01.511092Z","iopub.execute_input":"2024-01-18T19:31:01.511499Z","iopub.status.idle":"2024-01-18T19:31:02.212400Z","shell.execute_reply.started":"2024-01-18T19:31:01.511470Z","shell.execute_reply":"2024-01-18T19:31:02.211472Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Download and transcribe videos\n\nIn this section, we download Youtube audio files using video ids, and generate transcripts for all audio files using Whisper from OpenAI.","metadata":{"id":"H72VD2Xh8P0J"}},{"cell_type":"code","source":"# Install yt-dlp to download YouTube videos\n!python -m pip install -U yt-dlp","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LPPy9Cjz5B8p","outputId":"cc3ddffd-2362-471e-e625-180474b8023a","execution":{"iopub.status.busy":"2024-01-18T19:31:45.774381Z","iopub.execute_input":"2024-01-18T19:31:45.774831Z","iopub.status.idle":"2024-01-18T19:31:57.468941Z","shell.execute_reply.started":"2024-01-18T19:31:45.774797Z","shell.execute_reply":"2024-01-18T19:31:57.467819Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Requirement already satisfied: yt-dlp in /opt/conda/lib/python3.10/site-packages (2023.12.30)\nRequirement already satisfied: mutagen in /opt/conda/lib/python3.10/site-packages (from yt-dlp) (1.47.0)\nRequirement already satisfied: pycryptodomex in /opt/conda/lib/python3.10/site-packages (from yt-dlp) (3.20.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from yt-dlp) (2023.11.17)\nRequirement already satisfied: requests<3,>=2.31.0 in /opt/conda/lib/python3.10/site-packages (from yt-dlp) (2.31.0)\nCollecting urllib3<3,>=1.26.17 (from yt-dlp)\n  Obtaining dependency information for urllib3<3,>=1.26.17 from https://files.pythonhosted.org/packages/96/94/c31f58c7a7f470d5665935262ebd7455c7e4c7782eb525658d3dbf4b9403/urllib3-2.1.0-py3-none-any.whl.metadata\n  Using cached urllib3-2.1.0-py3-none-any.whl.metadata (6.4 kB)\nRequirement already satisfied: websockets>=12.0 in /opt/conda/lib/python3.10/site-packages (from yt-dlp) (12.0)\nRequirement already satisfied: brotli in /opt/conda/lib/python3.10/site-packages (from yt-dlp) (1.1.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.31.0->yt-dlp) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.31.0->yt-dlp) (3.4)\nUsing cached urllib3-2.1.0-py3-none-any.whl (104 kB)\nInstalling collected packages: urllib3\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.26.16\n    Uninstalling urllib3-1.26.16:\n      Successfully uninstalled urllib3-1.26.16\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbotocore 1.33.13 requires urllib3<2.1,>=1.25.4; python_version >= \"3.10\", but you have urllib3 2.1.0 which is incompatible.\ngoogle-auth 2.22.0 requires urllib3<2.0, but you have urllib3 2.1.0 which is incompatible.\nkfp 2.0.1 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.0.1 requires urllib3<2.0.0, but you have urllib3 2.1.0 which is incompatible.\ntensorflowjs 4.15.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed urllib3-2.1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Larger test data\nvideo_ids = [\n    'opMZib2qqeM',\n    'ccRbCkdjgpQ',\n    'Y3VI643ZtZY',\n    '1hB0pIrDtwY',\n    'KrFr_-f9PgA',\n    'g5V-lC7pai8',\n    '6A-RM62y8_U',\n    'wABigIrbOLk',\n    'SQJo_iL_AHY',\n    'c7V0A4aG-4U',\n    'u_dxgcYDkec',\n    'wxyjT4ik9jo',\n    '6y4QO0crrCo',\n    '6u27INGhmAI',\n    'OlOwd8ss1AI'\n]\ntitles = ['episode_325_large.vtt']*5 + ['episode_324_large.vtt']*5 + ['episode_323_large.vtt']*5","metadata":{"id":"s0Q2c91N7hwJ","execution":{"iopub.status.busy":"2024-01-18T22:24:55.981869Z","iopub.execute_input":"2024-01-18T22:24:55.982401Z","iopub.status.idle":"2024-01-18T22:24:55.988180Z","shell.execute_reply.started":"2024-01-18T22:24:55.982366Z","shell.execute_reply":"2024-01-18T22:24:55.987195Z"},"trusted":true},"execution_count":238,"outputs":[]},{"cell_type":"code","source":"# Smaller test data\nvideo_ids = [\n    'opMZib2qqeM',\n    'g5V-lC7pai8',\n    'u_dxgcYDkec',\n]\ntitles = ['episode_325_large.vtt', 'episode_324_large.vtt', 'episode_323_large.vtt']","metadata":{"id":"il_AIKu5D3N2","execution":{"iopub.status.busy":"2024-01-18T22:25:01.286490Z","iopub.execute_input":"2024-01-18T22:25:01.286914Z","iopub.status.idle":"2024-01-18T22:25:01.292445Z","shell.execute_reply.started":"2024-01-18T22:25:01.286880Z","shell.execute_reply":"2024-01-18T22:25:01.291340Z"},"trusted":true},"execution_count":240,"outputs":[]},{"cell_type":"code","source":"vid2gt_title = {}\nfor vid, title in zip(video_ids, titles):\n    vid2gt_title[vid] = title\n    \nprint(vid2gt_title)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T22:28:21.597285Z","iopub.execute_input":"2024-01-18T22:28:21.597975Z","iopub.status.idle":"2024-01-18T22:28:21.602931Z","shell.execute_reply.started":"2024-01-18T22:28:21.597926Z","shell.execute_reply":"2024-01-18T22:28:21.602169Z"},"trusted":true},"execution_count":244,"outputs":[{"name":"stdout","text":"{'opMZib2qqeM': 'episode_325_large.vtt', 'g5V-lC7pai8': 'episode_324_large.vtt', 'u_dxgcYDkec': 'episode_323_large.vtt'}\n","output_type":"stream"}]},{"cell_type":"code","source":"AUDIO_PATH = f'{INPUT_PATH}/audio'\n!mkdir -p $AUDIO_PATH","metadata":{"id":"LQIBSkAV-wa_","execution":{"iopub.status.busy":"2024-01-18T19:32:41.590870Z","iopub.execute_input":"2024-01-18T19:32:41.591762Z","iopub.status.idle":"2024-01-18T19:32:42.597825Z","shell.execute_reply.started":"2024-01-18T19:32:41.591724Z","shell.execute_reply":"2024-01-18T19:32:42.596355Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Add parallelism\nfor vid in video_ids:\n  mp3_file = f'{AUDIO_PATH}/{vid}.mp3'\n  !yt-dlp -x --audio-format mp3 -o $mp3_file -- $vid","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ltUQeYi9-0mF","outputId":"be8ee5f1-f164-47eb-df10-96feb36b10fd","execution":{"iopub.status.busy":"2024-01-18T19:32:43.814702Z","iopub.execute_input":"2024-01-18T19:32:43.815825Z","iopub.status.idle":"2024-01-18T19:33:24.977006Z","shell.execute_reply.started":"2024-01-18T19:32:43.815782Z","shell.execute_reply":"2024-01-18T19:33:24.976028Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"[youtube] Extracting URL: opMZib2qqeM\n[youtube] opMZib2qqeM: Downloading webpage\n[youtube] opMZib2qqeM: Downloading ios player API JSON\n[youtube] opMZib2qqeM: Downloading android player API JSON\n[youtube] opMZib2qqeM: Downloading m3u8 information\n[info] opMZib2qqeM: Downloading 1 format(s): 251\n[download] Destination: /kaggle/working/input/audio/opMZib2qqeM.webm\n\u001b[K[download] 100% of    2.79MiB in \u001b[1;37m00:00:00\u001b[0m at \u001b[0;32m13.15MiB/s\u001b[0m;33m00:00\u001b[0m\n[ExtractAudio] Destination: /kaggle/working/input/audio/opMZib2qqeM.mp3\nDeleting original file /kaggle/working/input/audio/opMZib2qqeM.webm (pass -k to keep)\n[youtube] Extracting URL: g5V-lC7pai8\n[youtube] g5V-lC7pai8: Downloading webpage\n[youtube] g5V-lC7pai8: Downloading ios player API JSON\n[youtube] g5V-lC7pai8: Downloading android player API JSON\n[youtube] g5V-lC7pai8: Downloading m3u8 information\n[info] g5V-lC7pai8: Downloading 1 format(s): 251\n[download] Destination: /kaggle/working/input/audio/g5V-lC7pai8.webm\n\u001b[K[download] 100% of    5.39MiB in \u001b[1;37m00:00:00\u001b[0m at \u001b[0;32m29.85MiB/s\u001b[0m;33m00:00\u001b[0m0m\n[ExtractAudio] Destination: /kaggle/working/input/audio/g5V-lC7pai8.mp3\nDeleting original file /kaggle/working/input/audio/g5V-lC7pai8.webm (pass -k to keep)\n[youtube] Extracting URL: u_dxgcYDkec\n[youtube] u_dxgcYDkec: Downloading webpage\n[youtube] u_dxgcYDkec: Downloading ios player API JSON\n[youtube] u_dxgcYDkec: Downloading android player API JSON\n[youtube] u_dxgcYDkec: Downloading m3u8 information\n[info] u_dxgcYDkec: Downloading 1 format(s): 251\n[download] Destination: /kaggle/working/input/audio/u_dxgcYDkec.webm\n\u001b[K[download] 100% of    4.53MiB in \u001b[1;37m00:00:00\u001b[0m at \u001b[0;32m25.91MiB/s\u001b[0m;33m00:00\u001b[0m0m\n[ExtractAudio] Destination: /kaggle/working/input/audio/u_dxgcYDkec.mp3\nDeleting original file /kaggle/working/input/audio/u_dxgcYDkec.webm (pass -k to keep)\n","output_type":"stream"}]},{"cell_type":"code","source":"!python -m pip install -U openai-whisper","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"az3R5yxQAv0y","outputId":"402b50c1-fbfd-4cf2-fedf-7c2725613466","execution":{"iopub.status.busy":"2024-01-18T19:33:30.747024Z","iopub.execute_input":"2024-01-18T19:33:30.747438Z","iopub.status.idle":"2024-01-18T19:34:01.992366Z","shell.execute_reply.started":"2024-01-18T19:33:30.747400Z","shell.execute_reply":"2024-01-18T19:34:01.991132Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Collecting openai-whisper\n  Downloading openai-whisper-20231117.tar.gz (798 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting triton<3,>=2.0.0 (from openai-whisper)\n  Obtaining dependency information for triton<3,>=2.0.0 from https://files.pythonhosted.org/packages/95/05/ed974ce87fe8c8843855daa2136b3409ee1c126707ab54a8b72815c08b49/triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (0.57.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (1.24.3)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (2.0.0+cpu)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (4.66.1)\nRequirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from openai-whisper) (10.1.0)\nCollecting tiktoken (from openai-whisper)\n  Obtaining dependency information for tiktoken from https://files.pythonhosted.org/packages/bf/56/a8910841d1f501cf8affeb06a0335a518888505c60ec9f2a2a6393190e48/tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton<3,>=2.0.0->openai-whisper) (3.12.2)\nRequirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->openai-whisper) (0.40.1)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken->openai-whisper) (2023.8.8)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken->openai-whisper) (2.31.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2023.11.17)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->openai-whisper) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->openai-whisper) (1.3.0)\nDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: openai-whisper\n  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801356 sha256=a70c0b30e6e072f0e73cb576e8c87a4e94f8ec04793b1c32392a488199f8d189\n  Stored in directory: /root/.cache/pip/wheels/d0/85/e1/9361b4cbea7dd4b7f6702fa4c3afc94877952eeb2b62f45f56\nSuccessfully built openai-whisper\nInstalling collected packages: triton, tiktoken, openai-whisper\nSuccessfully installed openai-whisper-20231117 tiktoken-0.5.2 triton-2.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import whisper\n\nMODEL_NAME = 'base' # tiny, base, small, medium, large\nmodel = whisper.load_model(MODEL_NAME)","metadata":{"id":"ZruL_8LVFEpV","execution":{"iopub.status.busy":"2024-01-18T19:34:05.890750Z","iopub.execute_input":"2024-01-18T19:34:05.891461Z","iopub.status.idle":"2024-01-18T19:34:15.666945Z","shell.execute_reply.started":"2024-01-18T19:34:05.891426Z","shell.execute_reply":"2024-01-18T19:34:15.665859Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"100%|███████████████████████████████████████| 139M/139M [00:03<00:00, 39.6MiB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test whisper model\nresult = model.transcribe(f\"{AUDIO_PATH}/{video_ids[0]}.mp3\")\nprint(result[\"text\"])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9KFPraRHA5fo","outputId":"54b59946-b6b6-4bb3-8900-81f333339f18","execution":{"iopub.status.busy":"2024-01-18T19:34:18.559127Z","iopub.execute_input":"2024-01-18T19:34:18.559657Z","iopub.status.idle":"2024-01-18T19:34:58.696674Z","shell.execute_reply.started":"2024-01-18T19:34:18.559622Z","shell.execute_reply":"2024-01-18T19:34:58.695563Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n","output_type":"stream"},{"name":"stdout","text":" So, as a fear to say, just like this idea that the laws of mathematics are discovered, they're latent within the fabric of the universe in that same way the laws of biology are kind of discovered. Yeah, I think that's absolutely, and it's probably not a popular view, but I think that's right on the money. Yeah. Well, I think that's a really deep idea. And embryogenesis is the process of revealing, of embodying, of manifesting these laws. You're not building the laws. Yeah. You're just creating the capacity to reveal. Yes. I think, again, not the standard view of molecular biology by any means, but I think that's right on the money. I'll give you a simple example. You know, some of our latest work with these xenobots, right? So what we've done is to take some skin cells off of an early frog embryo. And basically ask about their plasticity. If we give you a chance to sort of reboot your multicellularity in a different context, what would you do? Because what you might assume by the thing about embryogenesis is that it's super reliable, right? It's very robust. And that really obscures some of its most interesting features. We get used to it. We get used to the fact that acorns make oak trees and frog eggs make frogs. And we say, well, what else is it going to make? That's what it makes. That's a standard story. But the reality is, and so you look at these skin cells and you say, well, what do they know how to do? Well, they know how to be a passive-boring, two-dimensional outer layer, keeping the bacteria from getting into the embryo. That's what they know how to do. Well, it turns out that if you take these skin cells and you remove the rest of the embryo, so you remove all of the rest of the cells. And you say, well, you're by yourself now. What do you want to do? So what they do is they form this little, this multi-little creature that runs around the dish. They have all kinds of incredible capacities. They navigate through mases. They have various behaviors that they do both independently and together. They have a, basically they implement von Neumann's dream of self-replication because if you sprinkle a bunch of loose cells into the dish, what they do is they run around, they collect those cells into little piles. They sort of mush them together until those little piles become the next generation of zonobots. So you've got this machine that builds copies of itself from loose material in its environment. One of this are things that you would have expected from the frog genome. In fact, there is a wild type, the genome is wild type. There's nothing wrong with their genetics. Nothing has been added, no nanomaterials, no genomic editing, nothing. And so what we have done there is engineered by subtraction, what you've done is you've removed the other cells that normally basically bully these cells into being skin cells. And you find out that what they really want to do is to be this, they want, they're default behaviors to be a zonobot. And in vivo, in the embryo, they get told to be skinned by these other cell types. And so now here comes this really interesting question that you just posed. When you ask where does the form of the tappel and the frog come from, the standard answer is, well, it's selection. So over millions of years, it's been shaped to produce this specific body with that's fit for froggy environments. Where does the shape of the zonobot come from? There's never been any zonobots. There's never been selection to be a good zonobot. These cells find themselves in the new environment. In 48 hours, they figure out how to be an entirely different proto organism with new capacities like kinematic cell replication. That's not how frogs or tappels replicate. We've made it impossible for them to replicate their normal way within a couple days these guys find a new way of doing it. That's not done anywhere else in the biosphere.\n","output_type":"stream"}]},{"cell_type":"code","source":"vid2text = {}\nfor vid in video_ids:\n  transcript = model.transcribe(f\"{AUDIO_PATH}/{vid}.mp3\")\n  vid2text[vid] = transcript['text']","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"voQUq22RCP3X","outputId":"637b1a68-fe68-487c-ba44-c9995146aadc","execution":{"iopub.status.busy":"2024-01-18T19:36:02.832572Z","iopub.execute_input":"2024-01-18T19:36:02.833737Z","iopub.status.idle":"2024-01-18T19:38:58.844422Z","shell.execute_reply.started":"2024-01-18T19:36:02.833694Z","shell.execute_reply":"2024-01-18T19:38:58.843357Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n/opt/conda/lib/python3.10/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n/opt/conda/lib/python3.10/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Text Search","metadata":{"id":"kjsEn6K5Euwb"}},{"cell_type":"markdown","source":"### Full-text search with Whoosh\n\nIn this section, we use the transcribed text to find the corresponding podcast. If we're successful, we should be able to find the correct podcast given snippets of the transcript.","metadata":{"id":"M_41-SqoPlim"}},{"cell_type":"code","source":"!python -m pip install Whoosh","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1oRFxM22Lw2W","outputId":"48755395-e7e2-4adc-a872-62b38f9df73f","execution":{"iopub.status.busy":"2024-01-18T19:39:01.342995Z","iopub.execute_input":"2024-01-18T19:39:01.343352Z","iopub.status.idle":"2024-01-18T19:39:13.464690Z","shell.execute_reply.started":"2024-01-18T19:39:01.343326Z","shell.execute_reply":"2024-01-18T19:39:13.463664Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Collecting Whoosh\n  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.8/468.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: Whoosh\nSuccessfully installed Whoosh-2.7.4\n","output_type":"stream"}]},{"cell_type":"code","source":"!mkdir -p $WORKING_PATH/indexdir","metadata":{"execution":{"iopub.status.busy":"2024-01-18T19:39:14.995814Z","iopub.execute_input":"2024-01-18T19:39:14.996225Z","iopub.status.idle":"2024-01-18T19:39:16.018615Z","shell.execute_reply.started":"2024-01-18T19:39:14.996192Z","shell.execute_reply":"2024-01-18T19:39:16.016870Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"!rm -r $WORKING_PATH/indexdir/*","metadata":{"execution":{"iopub.status.busy":"2024-01-18T21:58:53.784976Z","iopub.execute_input":"2024-01-18T21:58:53.785354Z","iopub.status.idle":"2024-01-18T21:58:54.896710Z","shell.execute_reply.started":"2024-01-18T21:58:53.785325Z","shell.execute_reply":"2024-01-18T21:58:54.895162Z"},"trusted":true},"execution_count":203,"outputs":[]},{"cell_type":"code","source":"from whoosh.index import create_in\nfrom whoosh.fields import *\n\nschema = Schema(title=TEXT(stored=True), content=TEXT(phrase=True))\nix = create_in(\"indexdir\", schema)","metadata":{"id":"-eHhdNXJKxnR","execution":{"iopub.status.busy":"2024-01-18T21:58:56.125192Z","iopub.execute_input":"2024-01-18T21:58:56.125678Z","iopub.status.idle":"2024-01-18T21:58:56.134537Z","shell.execute_reply.started":"2024-01-18T21:58:56.125638Z","shell.execute_reply":"2024-01-18T21:58:56.133261Z"},"trusted":true},"execution_count":204,"outputs":[]},{"cell_type":"code","source":"writer = ix.writer()\nfor fname, text in zip(filenames, transcripts):\n#   print(fname, text[:100])\n  writer.add_document(title=fname, content=text)\nwriter.commit()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"05wzHVMYMTkd","outputId":"d2407c39-66dd-404f-ec01-4d6790643044","execution":{"iopub.status.busy":"2024-01-18T23:11:00.638554Z","iopub.execute_input":"2024-01-18T23:11:00.639085Z","iopub.status.idle":"2024-01-18T23:11:40.294285Z","shell.execute_reply.started":"2024-01-18T23:11:00.639043Z","shell.execute_reply":"2024-01-18T23:11:40.292153Z"},"trusted":true},"execution_count":267,"outputs":[]},{"cell_type":"code","source":"# Deprecated\nfrom whoosh.query import FuzzyTerm\n\nclass MyFuzzyTerm(FuzzyTerm):\n     def __init__(self, fieldname, text, boost=1.0, maxdist=3, prefixlength=1, constantscore=True):\n         super(MyFuzzyTerm, self).__init__(fieldname, text, boost, maxdist, prefixlength, constantscore)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T21:50:44.362241Z","iopub.execute_input":"2024-01-18T21:50:44.362974Z","iopub.status.idle":"2024-01-18T21:50:44.368292Z","shell.execute_reply.started":"2024-01-18T21:50:44.362925Z","shell.execute_reply":"2024-01-18T21:50:44.367283Z"},"trusted":true},"execution_count":197,"outputs":[]},{"cell_type":"code","source":"# Test\nfrom whoosh.qparser import QueryParser\n\n# text = \"So, as a fear to say, just like this idea that the laws of mathematics are discovered, they're latent within the fabric of the universe in that same way the laws of biology are kind of discovered.\"\n# text = \"There's a cold absurdity to the fact that you can play extremely well and still lose. I mean, actua~50\"\ntext = \"What about impressions? Is there similarity between that and acting? Is there some fundamental way in which you become the person? If you have a couple of the things, you can just fill in the blanks.\"\n\ntitle2count = {}\nparser = QueryParser(\"content\", ix.schema)\nwith ix.searcher() as searcher:\n    word_list = text.split(' ')\n#     print(word_list)\n    for i in range(len(word_list)-2):\n#         print(f'word: {word}')\n        query_text = ' '.join(word_list[i: i+3])\n#         print(query_text)\n        query = parser.parse('\"%s\"'%query_text)\n#         print(query)\n        results = searcher.search(query)\n        if len(results) == 0:\n            continue\n#         print(f'{len(results)} results')\n        for res in results:\n#             print(res['title'], fname2idx[res['title']])\n            title = res['title']\n            if title in title2count:\n                title2count[title] += 1\n            else:\n                title2count[title] = 1\n# print(title2count)\nmax(title2count, key=title2count.get)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":339},"id":"k05kqfg_M6j2","outputId":"1d5d304c-d2ce-43c5-8dea-2ff629462ed1","execution":{"iopub.status.busy":"2024-01-18T23:12:07.948463Z","iopub.execute_input":"2024-01-18T23:12:07.948837Z","iopub.status.idle":"2024-01-18T23:12:09.772821Z","shell.execute_reply.started":"2024-01-18T23:12:07.948807Z","shell.execute_reply":"2024-01-18T23:12:09.772032Z"},"trusted":true},"execution_count":271,"outputs":[{"execution_count":271,"output_type":"execute_result","data":{"text/plain":"'episode_325_large.vtt'"},"metadata":{}}]},{"cell_type":"code","source":"import six\n\nMAX_LENGTH = 200\nNUM_WORDS = 3\n\nparser = QueryParser(\"content\", ix.schema)\nwith ix.searcher() as searcher:\n  for vid, text in six.iteritems(vid2text):\n    title2count = {}\n    word_list = text[:min(MAX_LENGTH, len(text))].split(' ')\n    for i in range(len(word_list)-NUM_WORDS+1):\n        query_text = ' '.join(word_list[i: i+3])\n        query = parser.parse('\"%s\"'%query_text)\n        results = searcher.search(query)\n        if len(results) == 0:\n            continue\n        for res in results:\n            title = res['title']\n            if title in title2count:\n                title2count[title] += 1\n            else:\n                title2count[title] = 1\n    title = max(title2count, key=title2count.get) # get title with max count\n    print(f'vid: {vid}, groundtruth: {vid2gt_title[vid]}, pred: {title}')","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":377},"id":"OW2FvUYkP3zV","outputId":"3dde2c2d-14a1-4ece-e329-ba67c9713d52","execution":{"iopub.status.busy":"2024-01-18T23:12:15.098936Z","iopub.execute_input":"2024-01-18T23:12:15.099611Z","iopub.status.idle":"2024-01-18T23:12:20.508515Z","shell.execute_reply.started":"2024-01-18T23:12:15.099572Z","shell.execute_reply":"2024-01-18T23:12:20.507352Z"},"trusted":true},"execution_count":272,"outputs":[{"name":"stdout","text":"vid: opMZib2qqeM, groundtruth: episode_325_large.vtt, pred: episode_325_large.vtt\nvid: g5V-lC7pai8, groundtruth: episode_324_large.vtt, pred: episode_324_large.vtt\nvid: u_dxgcYDkec, groundtruth: episode_323_large.vtt, pred: episode_323_large.vtt\n","output_type":"stream"}]},{"cell_type":"markdown","source":"As we can see here, with the help of a full-text search engine `Whoosh`, we are able to find the correct podcast given the transcript generated by audio file.","metadata":{}},{"cell_type":"markdown","source":"### Full-text Search with ElasicSearch\n\n**NOTE: This section not finished yet.**\n\nhttps://colab.research.google.com/github/tensorflow/io/blob/master/docs/tutorials/elasticsearch.ipynb#scrollTo=YUj0878jPyz7","metadata":{"id":"5O3cwr94PX6i"}},{"cell_type":"code","source":"!python -m pip install elasticsearch","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cKuIODbyGghT","outputId":"9b697623-705f-484d-9ea6-d0ca1c168b41"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":"Collecting elasticsearch\n\n  Downloading elasticsearch-8.11.1-py3-none-any.whl (412 kB)\n\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.8/412.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hCollecting elastic-transport<9,>=8 (from elasticsearch)\n\n  Downloading elastic_transport-8.11.0-py3-none-any.whl (59 kB)\n\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.8/59.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hRequirement already satisfied: urllib3<3,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8->elasticsearch) (2.0.7)\n\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8->elasticsearch) (2023.11.17)\n\nInstalling collected packages: elastic-transport, elasticsearch\n\nSuccessfully installed elastic-transport-8.11.0 elasticsearch-8.11.1\n"}]},{"cell_type":"code","source":"from elasticsearch import Elasticsearch","metadata":{"id":"ZzohJzY0EVri"},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"# Initialize the Elasticsearch client\nes = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n# Create an index\nes.indices.create(index='my_index', ignore=400)\n# Index a document\ndocument = {\n    'title': 'Getting Started with Elasticsearch',\n    'content': 'Elasticsearch is a powerful search engine.',\n}\nes.index(index='my_index', doc_type='document', id=1, body=document)","metadata":{"id":"CoZfYpa-Gfqm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Search for documents\nsearch_results = es.search(index='my_index', body={'query': {'match': {'content': 'powerful search engine'}}})","metadata":{"id":"d9M_6VxhGrbr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the results\nfor hit in search_results['hits']['hits']:\n    print(f\"Document ID: {hit['_id']}, Score: {hit['_score']}\")","metadata":{"id":"d8sd9_KNGr-y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime\nfrom elasticsearch import Elasticsearch","metadata":{"id":"LQnWDMJDHBZo"},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"es = Elasticsearch(hosts = [{\"host\":\"localhost\", \"port\":9200, \"scheme\": \"https\"}])\n\ndoc = {\n    'author': 'kimchy',\n    'text': 'Elasticsearch: cool. bonsai cool.',\n    'timestamp': datetime.now(),\n}\nresp = es.index(index=\"test-index\", id=1, document=doc)\nprint(resp['result'])\n\nresp = es.get(index=\"test-index\", id=1)\nprint(resp['_source'])\n\nes.indices.refresh(index=\"test-index\")\n\nresp = es.search(index=\"test-index\", query={\"match_all\": {}})\nprint(\"Got %d Hits:\" % resp['hits']['total']['value'])\nfor hit in resp['hits']['hits']:\n    print(\"%(timestamp)s %(author)s: %(text)s\" % hit[\"_source\"])","metadata":{"id":"77WP9yRlG3zA"},"execution_count":null,"outputs":[]}]}